
# ![](https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png) Project 2: Billboard Hits + Data Munging
#### Due Wednesday, October 5, 9 am

### Overview

This week we learn how to manipulate data in Pandas, craft appropriate problem statements and work with pivot tables. Additionally, we are learning to clean data and use dummy variables. Now, let's apply some of these newly acquired skills in our second project. Given a dirty dataset, you will do exploratory data analysis. You will create a Jupyter notebook writeup for the dataset, with visualizations, statistical analysis, and documented data cleaning methodologies.

As an aside, you should get used to hearing this statistic: 80% of data analysis is spent on the process of cleaning and preparing the data, also known as EDA (Dasu and Johnson 2003). When you're looking at raw data, preparing for an interview or starting a new project, keep that in mind. Good models cannot produce good predictions without _good data_.

#### Project Summary

On next week's episode of the 'Are You Entertained?' podcast, we're going to be analyzing the latest generation's guilty pleasure- the music of the '00s. Our data scientists have poured through Billboard chart data to analyze what made a hit soar to the top of the charts, and how long they stayed there. Tune in next week for an awesome exploration of music and data as we continue to address an omnipresent question in the industry- _why do we like what we like?_

For this project, we'll be posting a companion writeup with visualizations that will offer insights into our conclusions.

**Deliverables**: a Jupyter technical notebook including plotting and statistical analysis, and a blog post describing your process and results.

---

### Requirements

Your work must:

- Include a problem statement
- State the risks and assumptions of your data
- Import data using the Pandas library
- Perform exploratory data analysis
- Use Tableau and/or Python plotting modules to visualize data
- Observe correlations in the data
- Evaluate a hypothesis
- Present results in a polished companion blog post of at least 500 words (& 1-2 graphics!)

---

### Necessary Deliverables

- Jupyter notebook, which must include your full analysis and be clearly commented.
- Your blog post, posted to your [username].github.io blog.
- Materials must be online, and links submitted to us, by the Wednesday morning of Week 3.

---

### Dataset

- [Dataset: Billboard Hits](./assets/billboard.csv)

---

### Suggested Ways to Get Started

- Read in your dataset
- Try out a few NumPy commands to describe your data
- Write pseudocode before you write actual code. Thinking through the logic of something helps.  
- Read the docs for whatever technologies you use. Most of the time, there is a tutorial that you can follow, but not always, and learning to read documentation is crucial to your success!
- Document **everything**.

---

### Project Feedback + Evaluation

[Attached here is a complete rubric for this project.](./project-02-rubric.md)

Your instructors will score each of your technical requirements using the scale below:

    Score | Expectations
    ----- | ------------
    **0** | _Incomplete._
    **1** | _Does not meet expectations._
    **2** | _Meets expectations, good job!_
    **3** | _Exceeds expectations, you wonderful creature, you!_

 This will serve as a helpful overall gauge of whether you met the project goals, but __the more important scores are the individual ones__ above, which can help you identify where to focus your efforts for the next project!
