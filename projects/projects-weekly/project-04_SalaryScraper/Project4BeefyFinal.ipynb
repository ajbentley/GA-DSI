{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import timeit\n",
    "import urllib2\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Scraping Data (Takes a couple minutes)\n",
    "salary = []\n",
    "company = []\n",
    "location = []\n",
    "jobs = []\n",
    "jobdescription = []\n",
    "for i in range(31):\n",
    "    url = \"http://www.careerbuilder.com/jobs-data-science?page_number=1&pay=20\"\n",
    "    index = 59\n",
    "    char = i\n",
    "    charplus = i + 1\n",
    "    charplusstring = str(charplus)\n",
    "    url2 = url[:index] + charplusstring + url[index + 1:]\n",
    "    rm = requests.get(url2)\n",
    "    soupm = BeautifulSoup(rm.content, \"lxml\")\n",
    "    \n",
    "    ###Appends job titles\n",
    "    for d in soupm.findAll(class_='job-title'):\n",
    "        jobs.append(d.text)\n",
    "        \n",
    "    ###Appends job descriptions\n",
    "    for d in soupm.findAll(class_='job-description show-for-medium-up'):\n",
    "        jobdescription.append(d.text)\n",
    "    \n",
    "    ###Appends salary, company, location.\n",
    "    z = 0\n",
    "    for d in soupm.findAll(class_='job-text'):\n",
    "        if z % 3 == 0:\n",
    "            salary.append(d.text)\n",
    "        elif z % 3 == 1:\n",
    "            company.append(d.text)\n",
    "        else:\n",
    "            location.append(d.text)\n",
    "        \n",
    "        z += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###Returning the lists to check\n",
    "#salary\n",
    "#company\n",
    "#location\n",
    "#jobs\n",
    "#jobdescription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Zipping them all together\n",
    "info = zip(salary, company, location, jobs, jobdescription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###Putting in DataFrame\n",
    "df = pd.DataFrame(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###Naming Columns\n",
    "df.columns = ('salary', 'company', 'location', 'title', 'description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###Breaking location into State/City\n",
    "df['state'] = [(x[-3:-1]) for x in df['location']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###Breaking location into City\n",
    "df['delete'] = df['location'].str.replace('\\n', '-------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['delete2'] = [(x[-80:-29]) for x in df['delete']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['delete3'] = df['delete2'].str.replace('-', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['city'] = df['delete3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del df['delete']\n",
    "del df['delete2']\n",
    "del df['delete3']\n",
    "del df['location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###Removing \\n from company\n",
    "df['company'] = df['company'].str.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Removing \\n from title\n",
    "df['title'] = df['title'].str.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Removing \\n from description\n",
    "df['description'] = df['description'].str.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###Creating a column for low end of salary\n",
    "df['low'] = [(x[18:22]) for x in df['salary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###Removing '$'\n",
    "df['low'] = df['low'].str.replace('$', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###Removing 'k'\n",
    "df['low'] = df['low'].str.replace('k', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###Removing '-'\n",
    "df['low'] = df['low'].str.replace('-', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###Removing ','\n",
    "df['low'] = df['low'].str.replace(',', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###Creating a column for high end of salary\n",
    "df['high'] = [(x[-11:-6]) for x in df['salary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###Removing '$'\n",
    "df['high'] = df['high'].str.replace('$', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Removing 'k'\n",
    "df['high'] = df['high'].str.replace('k', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Removing '-'\n",
    "df['high'] = df['high'].str.replace('-', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Removing ','\n",
    "df['high'] = df['high'].str.replace(',', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###Fixing '\\nFull'\n",
    "df['high'] = df['high'].str.replace('\\nFull', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "salary         object\n",
       "company        object\n",
       "title          object\n",
       "description    object\n",
       "state          object\n",
       "city           object\n",
       "low            object\n",
       "high           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###START OF CODE TO FIX NANS AND CONVERT TO INTEGERS\n",
    "dftest = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###Turning emptys into nans and dropping\n",
    "dftest['high'].replace('', np.nan, inplace=True)\n",
    "dftest['low'].replace('', np.nan, inplace=True)\n",
    "dftest.dropna(subset=['high'], inplace=True)\n",
    "dftest.dropna(subset=['low'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Turning remaining emptys into 0\n",
    "dftest['high']=dftest['high'].replace('', '0')\n",
    "dftest['low']=dftest['low'].replace('', '0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###Overriding error to return 0s and ints\n",
    "testing = df['high']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def replace_nulls(x):\n",
    "    try:\n",
    "        return int(x)\n",
    "    except:\n",
    "        '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testing = testing.apply(replace_nulls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#testing.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lowtest = df['low']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lowtest = lowtest.apply(replace_nulls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lowtest.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lowtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###putting together for a dataframe\n",
    "salarycolumns = zip(lowtest, testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "salarycolumnsframe = pd.DataFrame(salarycolumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = pd.concat([df, salarycolumnsframe], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Renaming Columns\n",
    "df2.columns = ('salary', 'company', 'title', 'description', 'state', 'city', 'low', 'high', 'lowsalary', 'highsalary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###Dropping Columns\n",
    "del df2['salary']\n",
    "del df2['low']\n",
    "del df2['high']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Getting Rid of Error Salaries\n",
    "def drop_outliers(x):\n",
    "    if x > 250:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fixer10 = df2['highsalary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fixer10 = fixer10.apply(drop_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Getting Rid of Error Salaries in the 'Low' Column\n",
    "def low_outliers(x):\n",
    "    if x > 5:\n",
    "        return x\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lowerfixer = df2['lowsalary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lowhighfix = zip(lowerfixer, fixer10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lowhigh = pd.DataFrame(lowhighfix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2 = pd.concat([df2, lowhigh], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2['low_salary'] = df2[0]\n",
    "df2['high_salary'] = df2[1]\n",
    "#df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Dropping Columns\n",
    "del df2[0]\n",
    "del df2[1]\n",
    "del df2['lowsalary']\n",
    "del df2['highsalary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.93603906062886"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Average Salary\n",
    "((df2['low_salary'].mean()) + (df2['high_salary'].mean())) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###Replacing Nans with Average\n",
    "def averages(x):\n",
    "    try:\n",
    "        return int(x)\n",
    "    except:\n",
    "        return 95.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tester94 = df2['low_salary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tester94 = tester94.apply(averages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "low_with_average = tester94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###Return the mean for 0.0 cells\n",
    "def zerofixer(x):\n",
    "    try:\n",
    "        return (x / 0) + x\n",
    "    except:\n",
    "        return 95.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "low_with_average = low_with_average.apply(zerofixer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "low_testing = tester94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "toaddagain = pd.DataFrame(low_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3 = pd.concat([df2, toaddagain], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df4 = df3.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df5 = df2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###Applying the original 'averages' function directly to the dataframe\n",
    "df5['low_salary'] = df5['low_salary'].apply(averages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df5['high_salary'] = df5['high_salary'].apply(averages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df6 = df5.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###Easier method. Returning the mean if salary is less than $5,000.\n",
    "def zeros_to_average(x):\n",
    "    if x < 5:\n",
    "        return 95.0\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df5['low_salary'] = df5['low_salary'].apply(zeros_to_average)\n",
    "df5['average_salary'] = (df5['low_salary'] + df5['high_salary']) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfreg = df5.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del dfreg['low_salary']\n",
    "del dfreg['high_salary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>average_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sancus Associates</td>\n",
       "      <td>Associate Data Science</td>\n",
       "      <td>Associate Data Scientist AdTech $125,000-150,0...</td>\n",
       "      <td>DC</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>137.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Analytic Recruiting</td>\n",
       "      <td>Associate, data Science and market Intelligence</td>\n",
       "      <td>Associate, data Science and market Intelligenc...</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tech Mahindra</td>\n",
       "      <td>BI Data Engineer</td>\n",
       "      <td>Position Title: BI Data Engineer Location: New...</td>\n",
       "      <td>OH</td>\n",
       "      <td>New Albany</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Challenge Charter School</td>\n",
       "      <td>6th grade Science &amp; Language Arts Teacher - Mi...</td>\n",
       "      <td>Arizona’s 1st Official Core Knowledge® School;...</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Glendale</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CyberCoders</td>\n",
       "      <td>Senior Data Scientist - be the first Data Scie...</td>\n",
       "      <td>This position is open as of 10/18/2016. Senior...</td>\n",
       "      <td>CA</td>\n",
       "      <td>Marina del Rey</td>\n",
       "      <td>175.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Medix</td>\n",
       "      <td>Research Scientist</td>\n",
       "      <td>Research Scientist This Research Scientist wil...</td>\n",
       "      <td>TX</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BIG WEDNESDAY DIGITAL</td>\n",
       "      <td>Junior Data Scientist - global eCommerce - Ban...</td>\n",
       "      <td>Junior Data Scientist - global eCommerce leade...</td>\n",
       "      <td>MD</td>\n",
       "      <td>Baltimore</td>\n",
       "      <td>97.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Burnett Specialists</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Job Reference #: 41-1014TBD-16CT Data Scientis...</td>\n",
       "      <td>TX</td>\n",
       "      <td>Houston</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BIG WEDNESDAY DIGITAL</td>\n",
       "      <td>Senior/Lead/NLP- Data Scientist - Bangkok role...</td>\n",
       "      <td>Senior/Lead/NLP- Data Scientist - Bangkok base...</td>\n",
       "      <td>WA</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>97.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Kelly Scientific Resources</td>\n",
       "      <td>Sr. Manager, Medical Data Methodology</td>\n",
       "      <td>Kelly Clinical and a highly reputable pharmace...</td>\n",
       "      <td>MA</td>\n",
       "      <td>Cambridge</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BIG WEDNESDAY DIGITAL</td>\n",
       "      <td>Data Scientist / Machine Learning Expert - Ban...</td>\n",
       "      <td>Data Scientist / Machine Learning Expert Pleas...</td>\n",
       "      <td>MA</td>\n",
       "      <td>Boston</td>\n",
       "      <td>97.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>endevis</td>\n",
       "      <td>Data Integration Developer</td>\n",
       "      <td>Endevis talent acquisition firm is working wit...</td>\n",
       "      <td>OH</td>\n",
       "      <td>Toledo</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CyberCoders</td>\n",
       "      <td>Data Product Manager</td>\n",
       "      <td>This position is open as of 10/18/2016. Data P...</td>\n",
       "      <td>CA</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BIG WEDNESDAY DIGITAL</td>\n",
       "      <td>Lead Data Scientist / Data Scientist Manager -...</td>\n",
       "      <td>Lead Data Scientist (Bangkok) - FULL RELOCATIO...</td>\n",
       "      <td>CA</td>\n",
       "      <td>Palo Alto</td>\n",
       "      <td>97.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Protege Hunters</td>\n",
       "      <td>Sales Engineer - Data Loss Protection Platform</td>\n",
       "      <td>TECHNICAL SALES ENGINEER - DATA SECURITY / DAT...</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Confidential</td>\n",
       "      <td>Big Data Engineer</td>\n",
       "      <td>Please send resume in Word format if you are i...</td>\n",
       "      <td>TX</td>\n",
       "      <td>Plano</td>\n",
       "      <td>77.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Emerald Resource Group</td>\n",
       "      <td>Data Architect</td>\n",
       "      <td>Data Architect - Healthcare Direct Hire/FTE Co...</td>\n",
       "      <td>OH</td>\n",
       "      <td>Columbus</td>\n",
       "      <td>102.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Confidential</td>\n",
       "      <td>Lead Big Data Engineer</td>\n",
       "      <td>Please send resume in Word format if you are i...</td>\n",
       "      <td>NY</td>\n",
       "      <td>Harrison</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Hellickson Associates</td>\n",
       "      <td>Data Center Engineer -Cisco</td>\n",
       "      <td>My client an IT services provide has an immedi...</td>\n",
       "      <td>WA</td>\n",
       "      <td>Spokane</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Kelly IT Resources</td>\n",
       "      <td>Junior MDM Data Analyst</td>\n",
       "      <td>Junior MDM Data Analyst This is an entry level...</td>\n",
       "      <td>MA</td>\n",
       "      <td>Lexington</td>\n",
       "      <td>27.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Analytic Recruiting</td>\n",
       "      <td>Marketing Sciences Manager</td>\n",
       "      <td>Marketing Sciences Manager Major Responsibilit...</td>\n",
       "      <td>CA</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Network Technologies International, Inc.</td>\n",
       "      <td>GIS Analyst I</td>\n",
       "      <td>Geographic Information Systems Analyst We are ...</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Scottsdale</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Cottonwood Financial</td>\n",
       "      <td>RISK ANALYST / STATISTICIAN</td>\n",
       "      <td>Reporting to the head of Risk and working clos...</td>\n",
       "      <td>TX</td>\n",
       "      <td>Irving</td>\n",
       "      <td>75.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Personnel Services Inc</td>\n",
       "      <td>Manager Field Agronomy</td>\n",
       "      <td>Manager Field Agronomy LOCATION: Kansas City, ...</td>\n",
       "      <td>MO</td>\n",
       "      <td>Kansas City</td>\n",
       "      <td>107.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Concurrent Technologies Corporation</td>\n",
       "      <td>SENIOR PRINCIPAL DATA SCIENTIST</td>\n",
       "      <td>AtConcurrent Technologies Corporation (CTC), w...</td>\n",
       "      <td>PA</td>\n",
       "      <td>Johnstown</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Aerotek</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Now hiring Data Scientists on DARPA's Net Defe...</td>\n",
       "      <td>VA</td>\n",
       "      <td>Arlington</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Analytic Recruiting</td>\n",
       "      <td>Marketing Sciences Manager</td>\n",
       "      <td>Marketing Sciences Manager Major Responsibilit...</td>\n",
       "      <td>CA</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>City and County of San Francisco</td>\n",
       "      <td>Data Clean Up and Conversion Lead</td>\n",
       "      <td>Data Clean Up and Conversion Lead $39.25 - $49...</td>\n",
       "      <td>CA</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>City and County of San Francisco</td>\n",
       "      <td>Data Conversion Strategy Supervisor</td>\n",
       "      <td>Data Conversion Strategy Supervisor $45.43 - $...</td>\n",
       "      <td>CA</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>94.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>CyberCoders</td>\n",
       "      <td>Data Visualization Engineer</td>\n",
       "      <td>This position is open as of 10/18/2016. Data V...</td>\n",
       "      <td>CA</td>\n",
       "      <td>Livermore</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>CyberCoders</td>\n",
       "      <td>Technical Writer</td>\n",
       "      <td>This position is open as of 10/18/2016. Techni...</td>\n",
       "      <td>CA</td>\n",
       "      <td>Redwood City</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>Cogensia</td>\n",
       "      <td>Senior Analyst, Strategic &amp; Analytic Solutions...</td>\n",
       "      <td>Cogensia is intelligence that compels; we are ...</td>\n",
       "      <td>IL</td>\n",
       "      <td>Schaumburg</td>\n",
       "      <td>72.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>Smiths Medical</td>\n",
       "      <td>Field Support Specialist</td>\n",
       "      <td>AtSmiths Medical, we are passionate about impr...</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>The Dubin Group</td>\n",
       "      <td>Project Assistant</td>\n",
       "      <td>Overview: Job ID 8929 Our client, a Clinical T...</td>\n",
       "      <td>PA</td>\n",
       "      <td>Wayne</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>Total Wine &amp; More</td>\n",
       "      <td>IT Security Engineer</td>\n",
       "      <td>Why Apply? Is it important for you be excited ...</td>\n",
       "      <td>DC</td>\n",
       "      <td>Washington</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>Kelly IT Resources</td>\n",
       "      <td>Help Desk - Field Sales Support Technician</td>\n",
       "      <td>Help Desk! Field Sales Support Technician need...</td>\n",
       "      <td>IN</td>\n",
       "      <td>Indianapolis</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>Sartori Company</td>\n",
       "      <td>Consumer Insights Manager</td>\n",
       "      <td>world award-winning cheeseto the finest retail...</td>\n",
       "      <td>WI</td>\n",
       "      <td>Plymouth</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>pathwayRP</td>\n",
       "      <td>Clinical Research Business Dev Manager</td>\n",
       "      <td>Our client is seeking a Business Development M...</td>\n",
       "      <td>PA</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>127.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>CSU</td>\n",
       "      <td>Research Associate 1</td>\n",
       "      <td>Description of Work Unit: Human Development an...</td>\n",
       "      <td>CO</td>\n",
       "      <td>Fort Collins</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>Ultimate</td>\n",
       "      <td>Human Resource Coordinator</td>\n",
       "      <td>A client in the Maryland Heights area is seeki...</td>\n",
       "      <td>MO</td>\n",
       "      <td>Saint Louis</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>Community Support Advocates</td>\n",
       "      <td>Case Manager</td>\n",
       "      <td>Provides care coordination for members; coordi...</td>\n",
       "      <td>IA</td>\n",
       "      <td>Des Moines</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>Real Staffing</td>\n",
       "      <td>Senior Regulatory Affairs Specialist</td>\n",
       "      <td>The Senior Regulatory Affairs Specialist creat...</td>\n",
       "      <td>WA</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>92.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>Mason Frank</td>\n",
       "      <td>Director of Sales Operations| Center Valley, P...</td>\n",
       "      <td>The Director of Salesforce Enablement is respo...</td>\n",
       "      <td>PA</td>\n",
       "      <td>Center Valley</td>\n",
       "      <td>170.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>Aerotek</td>\n",
       "      <td>Lab Associate - Project Management</td>\n",
       "      <td>Aerotek Scientific is looking for Lab Techs in...</td>\n",
       "      <td>CA</td>\n",
       "      <td>Valencia</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>The Institute for Transfusion Medicine</td>\n",
       "      <td>IT Help Desk Analyst</td>\n",
       "      <td>The IT Help Desk Analyst Delivers 1st level He...</td>\n",
       "      <td>PA</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>38.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>Pride Industries</td>\n",
       "      <td>Case Manager</td>\n",
       "      <td>PRIDE Industries is a fast-paced company with ...</td>\n",
       "      <td>CA</td>\n",
       "      <td>Roseville</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>CyberCoders</td>\n",
       "      <td>Bioinformatics Scientist - \"Top 10 Pharma/Biot...</td>\n",
       "      <td>This position is open as of 10/18/2016. Bioinf...</td>\n",
       "      <td>CA</td>\n",
       "      <td>Menlo Park</td>\n",
       "      <td>92.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>Ajilon Professional Staffing</td>\n",
       "      <td>Marketing Specialist</td>\n",
       "      <td>Marketing Specialist Mount Olive, NJ $60-80k O...</td>\n",
       "      <td>NJ</td>\n",
       "      <td>Mount Olive Township</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>Confidential</td>\n",
       "      <td>Storage Engineer - Senior OR Lead Storage Engi...</td>\n",
       "      <td>Role &amp; Responsibilities - Responsible for effe...</td>\n",
       "      <td>MA</td>\n",
       "      <td>Burlington</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>Apple &amp; Associates</td>\n",
       "      <td>Clinical Support Specialist</td>\n",
       "      <td>Our client is a leading manufacturer of Medica...</td>\n",
       "      <td>NC</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>98.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>The Ascent Services Group</td>\n",
       "      <td>Associate Director of Strategic IT and Telecom...</td>\n",
       "      <td>Job Title: Associate Director of Strategic IT ...</td>\n",
       "      <td>MA</td>\n",
       "      <td>Billerica</td>\n",
       "      <td>155.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>Randstad USA</td>\n",
       "      <td>Payroll Specialist - Raleigh</td>\n",
       "      <td>SEEKING PAYROLL SPECIALIST IN RALEIGH! PLEASE ...</td>\n",
       "      <td>NC</td>\n",
       "      <td>Raleigh</td>\n",
       "      <td>42.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>Affirma Consulting</td>\n",
       "      <td>Microsoft Dynamics CRM Developer</td>\n",
       "      <td>At Affirma Consulting the CRM Practice is resp...</td>\n",
       "      <td>WA</td>\n",
       "      <td>Bellevue</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>BrainWorks</td>\n",
       "      <td>Recruiting Account Executive</td>\n",
       "      <td>Recruiting Account Executive: LEARN TO BE A RE...</td>\n",
       "      <td>NJ</td>\n",
       "      <td>New Providence</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>Chickasaw Nation Industries</td>\n",
       "      <td>Policy Analyst (FDA OIP &amp; OPHT)</td>\n",
       "      <td>In support of the U.S. Department of Health an...</td>\n",
       "      <td>MD</td>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>49.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>Genpact Pharmalink</td>\n",
       "      <td>Associate Program Director, Commercial RA</td>\n",
       "      <td>Associate Program Director, PRC (E4) is an exp...</td>\n",
       "      <td>CA</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>Confidential</td>\n",
       "      <td>Web and Database Manager</td>\n",
       "      <td>Pomeroy is seeking a Web and Database Manager ...</td>\n",
       "      <td>KS</td>\n",
       "      <td>Mission</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>Meridian Group</td>\n",
       "      <td>Business Analyst / Reporting Analyst</td>\n",
       "      <td>Leading Education solutions provider seeking t...</td>\n",
       "      <td>IN</td>\n",
       "      <td>Indianapolis</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>Vaco Technology</td>\n",
       "      <td>Director of Solution Architecture - Banking</td>\n",
       "      <td>IT management professionals, take your career ...</td>\n",
       "      <td>NC</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>155.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>CyberCoders</td>\n",
       "      <td>Director of Customer Analytics</td>\n",
       "      <td>This position is open as of 10/18/2016. Direct...</td>\n",
       "      <td>CA</td>\n",
       "      <td>El Segundo</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>748 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      company  \\\n",
       "0                           Sancus Associates   \n",
       "1                         Analytic Recruiting   \n",
       "2                               Tech Mahindra   \n",
       "3                    Challenge Charter School   \n",
       "4                                 CyberCoders   \n",
       "5                                       Medix   \n",
       "6                       BIG WEDNESDAY DIGITAL   \n",
       "7                         Burnett Specialists   \n",
       "8                       BIG WEDNESDAY DIGITAL   \n",
       "9                  Kelly Scientific Resources   \n",
       "10                      BIG WEDNESDAY DIGITAL   \n",
       "11                                    endevis   \n",
       "12                                CyberCoders   \n",
       "13                      BIG WEDNESDAY DIGITAL   \n",
       "14                            Protege Hunters   \n",
       "15                               Confidential   \n",
       "16                     Emerald Resource Group   \n",
       "17                               Confidential   \n",
       "18                      Hellickson Associates   \n",
       "19                         Kelly IT Resources   \n",
       "20                        Analytic Recruiting   \n",
       "21   Network Technologies International, Inc.   \n",
       "22                       Cottonwood Financial   \n",
       "23                     Personnel Services Inc   \n",
       "24        Concurrent Technologies Corporation   \n",
       "25                                    Aerotek   \n",
       "26                        Analytic Recruiting   \n",
       "27           City and County of San Francisco   \n",
       "28           City and County of San Francisco   \n",
       "29                                CyberCoders   \n",
       "..                                        ...   \n",
       "718                               CyberCoders   \n",
       "719                                  Cogensia   \n",
       "720                            Smiths Medical   \n",
       "721                           The Dubin Group   \n",
       "722                         Total Wine & More   \n",
       "723                        Kelly IT Resources   \n",
       "724                           Sartori Company   \n",
       "725                                 pathwayRP   \n",
       "726                                       CSU   \n",
       "727                                  Ultimate   \n",
       "728               Community Support Advocates   \n",
       "729                             Real Staffing   \n",
       "730                               Mason Frank   \n",
       "731                                   Aerotek   \n",
       "732    The Institute for Transfusion Medicine   \n",
       "733                          Pride Industries   \n",
       "734                               CyberCoders   \n",
       "735              Ajilon Professional Staffing   \n",
       "736                              Confidential   \n",
       "737                        Apple & Associates   \n",
       "738                 The Ascent Services Group   \n",
       "739                              Randstad USA   \n",
       "740                        Affirma Consulting   \n",
       "741                                BrainWorks   \n",
       "742               Chickasaw Nation Industries   \n",
       "743                        Genpact Pharmalink   \n",
       "744                              Confidential   \n",
       "745                            Meridian Group   \n",
       "746                           Vaco Technology   \n",
       "747                               CyberCoders   \n",
       "\n",
       "                                                 title  \\\n",
       "0                               Associate Data Science   \n",
       "1      Associate, data Science and market Intelligence   \n",
       "2                                     BI Data Engineer   \n",
       "3    6th grade Science & Language Arts Teacher - Mi...   \n",
       "4    Senior Data Scientist - be the first Data Scie...   \n",
       "5                                   Research Scientist   \n",
       "6    Junior Data Scientist - global eCommerce - Ban...   \n",
       "7                                       Data Scientist   \n",
       "8    Senior/Lead/NLP- Data Scientist - Bangkok role...   \n",
       "9                Sr. Manager, Medical Data Methodology   \n",
       "10   Data Scientist / Machine Learning Expert - Ban...   \n",
       "11                          Data Integration Developer   \n",
       "12                                Data Product Manager   \n",
       "13   Lead Data Scientist / Data Scientist Manager -...   \n",
       "14      Sales Engineer - Data Loss Protection Platform   \n",
       "15                                   Big Data Engineer   \n",
       "16                                      Data Architect   \n",
       "17                              Lead Big Data Engineer   \n",
       "18                         Data Center Engineer -Cisco   \n",
       "19                             Junior MDM Data Analyst   \n",
       "20                          Marketing Sciences Manager   \n",
       "21                                       GIS Analyst I   \n",
       "22                         RISK ANALYST / STATISTICIAN   \n",
       "23                              Manager Field Agronomy   \n",
       "24                     SENIOR PRINCIPAL DATA SCIENTIST   \n",
       "25                                      Data Scientist   \n",
       "26                          Marketing Sciences Manager   \n",
       "27                   Data Clean Up and Conversion Lead   \n",
       "28                 Data Conversion Strategy Supervisor   \n",
       "29                         Data Visualization Engineer   \n",
       "..                                                 ...   \n",
       "718                                   Technical Writer   \n",
       "719  Senior Analyst, Strategic & Analytic Solutions...   \n",
       "720                           Field Support Specialist   \n",
       "721                                  Project Assistant   \n",
       "722                               IT Security Engineer   \n",
       "723         Help Desk - Field Sales Support Technician   \n",
       "724                          Consumer Insights Manager   \n",
       "725             Clinical Research Business Dev Manager   \n",
       "726                               Research Associate 1   \n",
       "727                         Human Resource Coordinator   \n",
       "728                                       Case Manager   \n",
       "729               Senior Regulatory Affairs Specialist   \n",
       "730  Director of Sales Operations| Center Valley, P...   \n",
       "731                 Lab Associate - Project Management   \n",
       "732                               IT Help Desk Analyst   \n",
       "733                                       Case Manager   \n",
       "734  Bioinformatics Scientist - \"Top 10 Pharma/Biot...   \n",
       "735                               Marketing Specialist   \n",
       "736  Storage Engineer - Senior OR Lead Storage Engi...   \n",
       "737                        Clinical Support Specialist   \n",
       "738  Associate Director of Strategic IT and Telecom...   \n",
       "739                       Payroll Specialist - Raleigh   \n",
       "740                   Microsoft Dynamics CRM Developer   \n",
       "741                       Recruiting Account Executive   \n",
       "742                    Policy Analyst (FDA OIP & OPHT)   \n",
       "743          Associate Program Director, Commercial RA   \n",
       "744                           Web and Database Manager   \n",
       "745               Business Analyst / Reporting Analyst   \n",
       "746        Director of Solution Architecture - Banking   \n",
       "747                     Director of Customer Analytics   \n",
       "\n",
       "                                           description state  \\\n",
       "0    Associate Data Scientist AdTech $125,000-150,0...    DC   \n",
       "1    Associate, data Science and market Intelligenc...    NY   \n",
       "2    Position Title: BI Data Engineer Location: New...    OH   \n",
       "3    Arizona’s 1st Official Core Knowledge® School;...    AZ   \n",
       "4    This position is open as of 10/18/2016. Senior...    CA   \n",
       "5    Research Scientist This Research Scientist wil...    TX   \n",
       "6    Junior Data Scientist - global eCommerce leade...    MD   \n",
       "7    Job Reference #: 41-1014TBD-16CT Data Scientis...    TX   \n",
       "8    Senior/Lead/NLP- Data Scientist - Bangkok base...    WA   \n",
       "9    Kelly Clinical and a highly reputable pharmace...    MA   \n",
       "10   Data Scientist / Machine Learning Expert Pleas...    MA   \n",
       "11   Endevis talent acquisition firm is working wit...    OH   \n",
       "12   This position is open as of 10/18/2016. Data P...    CA   \n",
       "13   Lead Data Scientist (Bangkok) - FULL RELOCATIO...    CA   \n",
       "14   TECHNICAL SALES ENGINEER - DATA SECURITY / DAT...    NY   \n",
       "15   Please send resume in Word format if you are i...    TX   \n",
       "16   Data Architect - Healthcare Direct Hire/FTE Co...    OH   \n",
       "17   Please send resume in Word format if you are i...    NY   \n",
       "18   My client an IT services provide has an immedi...    WA   \n",
       "19   Junior MDM Data Analyst This is an entry level...    MA   \n",
       "20   Marketing Sciences Manager Major Responsibilit...    CA   \n",
       "21   Geographic Information Systems Analyst We are ...    AZ   \n",
       "22   Reporting to the head of Risk and working clos...    TX   \n",
       "23   Manager Field Agronomy LOCATION: Kansas City, ...    MO   \n",
       "24   AtConcurrent Technologies Corporation (CTC), w...    PA   \n",
       "25   Now hiring Data Scientists on DARPA's Net Defe...    VA   \n",
       "26   Marketing Sciences Manager Major Responsibilit...    CA   \n",
       "27   Data Clean Up and Conversion Lead $39.25 - $49...    CA   \n",
       "28   Data Conversion Strategy Supervisor $45.43 - $...    CA   \n",
       "29   This position is open as of 10/18/2016. Data V...    CA   \n",
       "..                                                 ...   ...   \n",
       "718  This position is open as of 10/18/2016. Techni...    CA   \n",
       "719  Cogensia is intelligence that compels; we are ...    IL   \n",
       "720  AtSmiths Medical, we are passionate about impr...    NY   \n",
       "721  Overview: Job ID 8929 Our client, a Clinical T...    PA   \n",
       "722  Why Apply? Is it important for you be excited ...    DC   \n",
       "723  Help Desk! Field Sales Support Technician need...    IN   \n",
       "724  world award-winning cheeseto the finest retail...    WI   \n",
       "725  Our client is seeking a Business Development M...    PA   \n",
       "726  Description of Work Unit: Human Development an...    CO   \n",
       "727  A client in the Maryland Heights area is seeki...    MO   \n",
       "728  Provides care coordination for members; coordi...    IA   \n",
       "729  The Senior Regulatory Affairs Specialist creat...    WA   \n",
       "730  The Director of Salesforce Enablement is respo...    PA   \n",
       "731  Aerotek Scientific is looking for Lab Techs in...    CA   \n",
       "732  The IT Help Desk Analyst Delivers 1st level He...    PA   \n",
       "733  PRIDE Industries is a fast-paced company with ...    CA   \n",
       "734  This position is open as of 10/18/2016. Bioinf...    CA   \n",
       "735  Marketing Specialist Mount Olive, NJ $60-80k O...    NJ   \n",
       "736  Role & Responsibilities - Responsible for effe...    MA   \n",
       "737  Our client is a leading manufacturer of Medica...    NC   \n",
       "738  Job Title: Associate Director of Strategic IT ...    MA   \n",
       "739  SEEKING PAYROLL SPECIALIST IN RALEIGH! PLEASE ...    NC   \n",
       "740  At Affirma Consulting the CRM Practice is resp...    WA   \n",
       "741  Recruiting Account Executive: LEARN TO BE A RE...    NJ   \n",
       "742  In support of the U.S. Department of Health an...    MD   \n",
       "743  Associate Program Director, PRC (E4) is an exp...    CA   \n",
       "744  Pomeroy is seeking a Web and Database Manager ...    KS   \n",
       "745  Leading Education solutions provider seeking t...    IN   \n",
       "746  IT management professionals, take your career ...    NC   \n",
       "747  This position is open as of 10/18/2016. Direct...    CA   \n",
       "\n",
       "                     city  average_salary  \n",
       "0    District of Columbia           137.5  \n",
       "1                New York           100.0  \n",
       "2              New Albany            95.0  \n",
       "3                Glendale            41.0  \n",
       "4          Marina del Rey           175.0  \n",
       "5                  Dallas            60.0  \n",
       "6               Baltimore            97.5  \n",
       "7                 Houston           100.0  \n",
       "8                 Seattle            97.5  \n",
       "9               Cambridge           110.0  \n",
       "10                 Boston            97.5  \n",
       "11                 Toledo            90.0  \n",
       "12          San Francisco           125.0  \n",
       "13              Palo Alto            97.5  \n",
       "14               New York           135.0  \n",
       "15                  Plano            77.5  \n",
       "16               Columbus           102.5  \n",
       "17               Harrison           120.0  \n",
       "18                Spokane            80.0  \n",
       "19              Lexington            27.5  \n",
       "20          San Francisco           125.0  \n",
       "21             Scottsdale            45.0  \n",
       "22                 Irving            75.5  \n",
       "23            Kansas City           107.5  \n",
       "24              Johnstown            95.0  \n",
       "25              Arlington            80.0  \n",
       "26          San Francisco           125.0  \n",
       "27          San Francisco            88.0  \n",
       "28          San Francisco            94.5  \n",
       "29              Livermore            95.0  \n",
       "..                    ...             ...  \n",
       "718          Redwood City           110.0  \n",
       "719            Schaumburg            72.5  \n",
       "720              New York            90.0  \n",
       "721                 Wayne            36.0  \n",
       "722            Washington           120.0  \n",
       "723          Indianapolis            20.0  \n",
       "724              Plymouth            95.0  \n",
       "725          Philadelphia           127.5  \n",
       "726          Fort Collins            50.0  \n",
       "727           Saint Louis            95.0  \n",
       "728            Des Moines            35.0  \n",
       "729               Seattle            92.5  \n",
       "730         Center Valley           170.0  \n",
       "731              Valencia            19.0  \n",
       "732            Pittsburgh            38.5  \n",
       "733             Roseville            95.0  \n",
       "734            Menlo Park            92.5  \n",
       "735  Mount Olive Township            75.0  \n",
       "736            Burlington           125.0  \n",
       "737             Charlotte            98.5  \n",
       "738             Billerica           155.0  \n",
       "739               Raleigh            42.5  \n",
       "740              Bellevue            80.0  \n",
       "741        New Providence            50.0  \n",
       "742         Silver Spring            49.5  \n",
       "743         San Francisco            95.0  \n",
       "744               Mission           100.0  \n",
       "745          Indianapolis            70.0  \n",
       "746             Charlotte           155.0  \n",
       "747            El Segundo           150.0  \n",
       "\n",
       "[748 rows x 6 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-74-4db67455f847>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-74-4db67455f847>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    dfreg['high_vs_low'] =\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "dfreg['high_vs_low'] ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Bucketing Income\n",
    "def bucket(x):\n",
    "    if x['average_salary'] > 95:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfreg2 = dfreg.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfreg2['high_vs_low'] = dfreg2.apply(bucket, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Now have complete dataset\n",
    "dfreg2['label'] = dfreg2['high_vs_low']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del dfreg2['high_vs_low']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = dfreg2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 'Data' is our final dataset </h1>\n",
    "<br>\n",
    "<p>\n",
    "After scraping 30 pages of search results for \"Data Science\" on careerbuilder.com, cleaning the data, and creating a binary column for 'high' vs 'low' salary we finally have our final dataframe. We determined salaries above the mean of $95,000 would be considered 'high' and anything else would be 'low'.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###Testing to see which words in 'Job Titles' correspond to higher salaries\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "v = CountVectorizer(\n",
    "    binary=True,  \n",
    "    stop_words='english', \n",
    "    max_features=50, \n",
    "\n",
    "\n",
    "X = v.fit_transform(data.title).todense()\n",
    "X = pd.DataFrame(X, columns=v.get_feature_names())\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = data.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to help examine the coefficients\n",
    "def examine_coefficients(model, df9):\n",
    "    df9 = pd.DataFrame(\n",
    "        { 'Coefficient' : model.coef_[0] , 'Feature' : df9.columns}\n",
    "    ).sort_values(by='Coefficient')\n",
    "    return df9[df9.Coefficient !=0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###Creates DataFrame of Coefficients for Job Title\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(penalty = 'l1', C = 1.0) # Model with high, little regularization\n",
    "\n",
    "model.fit(X, y)\n",
    "datatitle = examine_coefficients(model, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###Testing to see how well the model performed\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "for metric in ['accuracy', 'precision', 'recall', 'roc_auc']:\n",
    "    scores = cross_val_score(model, X, y, scoring=metric)\n",
    "    print(\"mean {}: {}, all: {}\".format(metric, scores.mean(), scores))\n",
    "    \n",
    "# mean roc_auc: 0.829"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Testing the Model </h1>\n",
    "<br>\n",
    "<p>\n",
    "Our model testing words in 'job title' to predict salary had an roc_auc score of 0.74, accuracy of .68, precision of .68, and recall of .59.\n",
    "</p>\n",
    "<p> The words in the job title that were the strongest indicators of low salary were 'level', 'coordinator', 'electrical', 'analyst', 'quality', 'supervisor', 'associate', and 'support'.\n",
    "</p>\n",
    "<p>\n",
    "The words in the job title that were the strongest indicators of high salaries were 'architect', 'infrastructure', 'director', 'manager', 'sr', 'senior', 'lead', and 'development'\n",
    "</p>\n",
    "<p>\n",
    "The words in job description that were the strongest indicators of high salaries were 'manager', 'responsible', 'experience', 'senior', 'business',  and 'growing'.\n",
    "</p>\n",
    "<p>\n",
    "The words in job description that were the strongest indicators of low salaries were 'analyst', 'position', 'job', 'support', 'opportunity', 'hire', 'new', 'systems', and 'time'.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datatitle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datadescription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###Model based on Description\n",
    "v = CountVectorizer(\n",
    "    binary=True,  # Create binary features\n",
    "    stop_words='english', # Ignore common words such as 'the', 'and'\n",
    "    max_features=50, # Only use the top 50 most common words\n",
    ")\n",
    "\n",
    "\n",
    "# This builds a matrix with a row per website (or data point) and column per word (using all words in the dataset)\n",
    "X = v.fit_transform(data.description).todense()\n",
    "X = pd.DataFrame(X, columns=v.get_feature_names())\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def examine_coefficients2(model, df10):\n",
    "    df10 = pd.DataFrame(\n",
    "        { 'Coefficient' : model.coef_[0] , 'Feature' : df10.columns}\n",
    "    ).sort_values(by='Coefficient')\n",
    "    return df10[df10.Coefficient !=0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(penalty = 'l1', C = 1.0) # Model with high, little regularization\n",
    "\n",
    "model.fit(X, y)\n",
    "datadescription = examine_coefficients(model, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import patsy\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###We also created a model based on City/State/Title/Description\n",
    "X = patsy.dmatrix('~C(city) + C(state) +C(company) + C(title) +C(description)' , data)\n",
    "y = data['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pdf = pd.DataFrame(X, columns=X.design_info.column_names)\n",
    "pdf['Target'] = y\n",
    "#pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_model = lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_ypred = lr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# actual = index; predicted = columns\n",
    "lr_cm = confusion_matrix(y_test, lr_ypred, labels=lr.classes_)\n",
    "lr_cm = pd.DataFrame(lr_cm, columns=lr.classes_, index=lr.classes_)\n",
    "lr_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print classification_report(y_test, lr_ypred, labels=lr.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_l1 = LogisticRegression(C=500, penalty='l1', solver='liblinear')\n",
    "lr_l1_model = lr_l1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_l1_model = lr_l1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_l1_ypred = lr_l1_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr_l1_cm = confusion_matrix(y_test, lr_l1_ypred, labels=lr_l1.classes_)\n",
    "lr_l1_cm = pd.DataFrame(lr_l1_cm, columns=lr_l1.classes_, index=lr_l1.classes_)\n",
    "lr_l1_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print classification_report(y_test, lr_l1_ypred, labels=lr_l1.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "Our model testing based on city, state, title, description, and company had an f1-score of .68 when we did a regular logistic regression and had an f1-score of .68 when we used an L1 with a C of 500.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
