{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes Intro Lab: review of distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building Bayesian models requires us to utilize common probability models for the likelihood function. These will include the usual suspects of binomial, Bernoulli, Cauchy, chi-squared, poison etc.\n",
    "\n",
    "\n",
    "|     Distribution  | Probability Mass Function (The Formula)  | Written Description \n",
    "|:-:|---|---|\n",
    "| Uniform  | $\\frac{1}{n}$ |  Basically, a uniform distribution is utilized when you're selecting any one member of a set is just as likely as any other  |\n",
    "| Bernoulli   | $\\binom{n}{k}\\cdot p^{k}(1-p)^{1-k} $  | Like a coin flip, p represents the probability that event X occurs, and 1-p is the probability that event Y occurs  |\n",
    "| Poisson | $\\frac{e^{-n}n^{x}}{x!}$ | The probability of observing x events in a certain time interval. e is the Euler number and n is a tuning parameter |\n",
    "| Binomial  | $\\binom{n}{k}\\cdot p^kq^{n-k} $| Gives you the probability of getting k \"success\" in n iterations/trials\n",
    "\n",
    "\n",
    "We'll do a review of counting and combinatorics, then introduce the Beta function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A small excursion into counting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ Binom(n,k) = \\binom{n}{k} \\cdot p^kq^{n-k} $$\n",
    "Where the binomial coefficient is read \"n choose k\". You should be familiar with this concept through your previous exposure to basic probability. However, in case you need to jog your memory, I'm going to go through some important properties of counting that are important to giving you a better intuitive grasp at the mechanics of Bernoulli, and hopefully, by extension Bayesian analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Factorials and Variations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A factorial is defined as n! = $n*(n-1)*...*1 = \\prod_{i=1}^{n} i$\n",
    "This often use to enumerate all the different possibly of a number of objects as you remove one after you've selected it. \n",
    " \n",
    "It uses something called the multiplication rule, which can be demonstrated common sensibly by thinking of ordering a Pizza. \n",
    "If you order a pizza, and there are 5 types of meats, 3 types of cheese, and 10 types of vegetables, then there are 5* 3 * 10. \n",
    "\n",
    "A variation is slightly more complicated (but useful) concept. A variation\n",
    " $V = \\frac{n!}{(n-k)!} $, and can be thought of as number of all k-element variations \"chosen\" from a set of n elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: How many 3 digit numbers can be constructed from the numeral 0,1,2,3,4,5,6,7,8,9?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Answer:** The solution to this question requires us to remember the product rule of sets/counting and some common sense. So clearly, a 3-digit number can be visualized thus _ _ _ , where each underscore has a certain number of possibilities, the number of 3-digit numbers therefore would just equal to the number of possibilities for the first position, times the number of possibilities for the second position, times the number of possibilities of the third. \n",
    "\n",
    "There are 10 numerals (0 - 9), therefore the third position has 10 possibilities, the same with the second. Yet the first only has 9, since 0 is not admissible (i.e. 090 is just 90). Therefore, the number of possibilities is just\n",
    " $9*10^2$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Combinations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going a little fast, but we've reached the cul-de-grace for this small aside: The combination formula. A combination $ C =  \\frac{n!}{(n-k)! (k!)} $ often denoted symbolically as $\\binom{n}{k}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we had 30 white non-distinct balls distributed to 10 people, with each person receiving one and only one ball. How many ways can this be accomplished such that each individual receives **AT LEAST** one ball?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** So let's take a simpler problem, suppose we only had 2 people to distribute from, how many different ways could we distribute 30 balls? You can have 30 - 0, 29 - 1, 28 - 2, etc. (basically the Gaussian trick of counting). If we were to visualize it, this could be solved by imposing the formula $\\binom{30 + 1}{1}=1$, which satisfies our intuition. However, we want to ensure that each person gets at least one ball, so what do we do? Simple, subtract 30-10 = 20, since we are holding at least 1 ball for each individual, therefore the new counting is just $\\binom{20+1}{1}$. \n",
    "\n",
    "Likewise, if we were to have 10 different people, we could simple use the formula $\\binom{30+10-1}{10-1}$ or to ensure each person gets a ball, $\\binom{30+10-10-1}{10-1}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we will see, the phenomena of coin tossing will be directly connected with understanding the number of configurations you have with a small number of non-distinct classes of objects (in this case heads or tails). We will now simulate a simple coin toss with the Bernoulli scheme. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating a Simple Fair Coin Toss with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to call some methods from scipy stats library. Let me emphasize, what the next following exercises (including those for the rest of this week -or course for that matter), can be accomplished in multiple ways. What we're trying to do is get you familiar with the methods available to you, so that you'll be ready to chain them up together to build your own (more complicated) methods as you mature in data science and start to do custom development for your work/startup/hobby whatever. \n",
    "\n",
    "If you need a review for what a random variable is, please refer to the following: https://www.khanacademy.org/math/probability/random-variables-topic/random-variables-prob-dist/v/discrete-and-continuous-random-variables, being that we are operating on computers, we will be utilizing discrete random variables. \n",
    "\n",
    "To start off, we should become familiar with the docs for scipy.stats. Please take some time and browse/read through the following site: http://docs.scipy.org/doc/scipy-0.17.0/reference/stats.html\n",
    "\n",
    "Scroll down and look through the **discrete distributions.** Read carefully what's there, play close attention to the standard methods attached to each distribution object. \n",
    "\n",
    "If you need a quick review of probability distributions go through this quick video here: https://www.youtube.com/watch?v=mrCxwEZ_22o\n",
    "\n",
    "When you're comfortable with what they do, and how to call them, try the exercises below. Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using scipy.stats create a simple vector of 100 coin flips for a fair coin and print the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Using Bernoulli to simulate a coin toss\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from scipy.stats import bernoulli \n",
    "import numpy as np\n",
    "\n",
    "prob = .5 \n",
    "bernol = bernoulli(prob)\n",
    "\n",
    "def bernol_scheme(n):\n",
    "    return bernol.rvs(n)# flip it n times\n",
    "\n",
    "print(bernol_scheme(100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building on Bernoulli to construct the Binomial distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to force you to explore (and use) some base libraries, like math. Why? Well, with libraries like scipy-stats, there are major benefits, namely they make calculating complicated objects (distributions, rvs, etc.) very easy. Yet, there is a cost, they may limit your freedom (you can only calculate a distribution a certain way possibly), and they bring in dependancies. In your early carrier, you will probably not stumble onto issues of library compatbilities, or \"collisions\", but dependancies will become important, especailly as you move into the frontier of the data science world. \n",
    "\n",
    "Therefore, every data scientist needs to be familiar with the base-libraries, and be prepared to utilize them directly to a problem if need be. \n",
    "\n",
    "Please read the following link, like above, read/browse the various methods, and when you're ready. Go ahead and try the following exericse.\n",
    "https://docs.python.org/2/library/math.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a simple combination function, using only your wits (and maybe the math library in Python - but nothing more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Before we proceed with the rest of the lab, we should disect the formula for Bernoulli, the distribution we will be playing \n",
    "# with the most. \n",
    "\n",
    "#Write the combination formula into Python from scratch. Do not call any combination method from any library!\n",
    "\n",
    "import math\n",
    "\n",
    "def Choose_Comb(n,r):\n",
    "    return math.factorial(n)/math.factorial(r)/math.factorial(n-r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using what you know about Bernoulli, Combinations, and Variations, build the Binomial distribution, plotting, \n",
    "(mostly) from scratch, the probability of you making k-heads (or tails) in n trials on a fair coin.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Hint, try a barplot or histogram with the x-axis accounting for the number of k-heads you want to model for n-trials. \n",
    "\n",
    "import math\n",
    "import pylab\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 10\n",
    "heads = 0.5; tails = 1 - heads;\n",
    "Comb_series = [1]\n",
    "\n",
    "def Choose_Comb(n,r):\n",
    "    return math.factorial(n)/math.factorial(r)/math.factorial(n-r)\n",
    "\n",
    "def x_axis_hash(n):\n",
    "    return [str(x) for x in range(n+1)]\n",
    "\n",
    "for x in range(1,n+1):\n",
    "    Comb_series = Comb_series + [Choose_Comb(n,x)]\n",
    "    \n",
    "prob = []\n",
    "\n",
    "for x in range(n+1):\n",
    "    prob = prob + [(Comb_series[x]*((heads**x)*(tails**(n-x))))*100]\n",
    "    \n",
    "x = numpy.arange(n+1)\n",
    "plt.bar(x, prob, color=\"blue\")\n",
    "plt.xticks(x+0.5, x_axis_hash(n))\n",
    "plt.show()   # Shows the graph of the number of heads for a fair coin after x trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Beside Bernoulli/Binomial distributions, we'll be using other distributions and family of distributions while constructing probability or simulation models. Poisson comes up often in Bayesian analysis as well. Use stats model to plot the Poisson distribution in a simple histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Use the scipy library to model and plot a Poisson scheme with a trial size of 100, \n",
    "\n",
    "\n",
    "from scipy import stats\n",
    "#from scipy.stats import poisson\n",
    "\n",
    "\n",
    "import pylab\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# We will load up Poisson distribution so you can \n",
    "\n",
    "poisson_trial = stats.poisson.rvs(mu = 2, loc = 0, size = 100)\n",
    "plt.figure()\n",
    "plt.hist(poisson_trial, bins = 5, normed = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preview of an upcoming deeper dive into Bayes - Introducing the Beta Function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the lesson, we discussed the importance of the prior in Bayesian analysis. In common speak, it's basically a person's \"beliefs\".\n",
    "\n",
    "We can model priors in the continuous domain (real numbers say from 0 to 1). To do this, we can take advantage of the Beta Function and assign it as our prior. For now, we will just start to play with the distribution, but it will be an integral part of the machinery of Bayesian inference. For this simple exercise below, please implement the beta distribution and select an alpha and beta hyper parameter that outputs a graph. \n",
    "\n",
    "Play with these parameters, notice anything as you change them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Hyper what? Introducing Betas and 'Hyperparameters'\n",
    "\n",
    "from scipy.stats import beta\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "a = 55\n",
    "b = 32\n",
    "x = np.arange (-100, 200, 0.1)\n",
    "y = beta.pdf(x,a,b, scale=100, loc=-100)\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
