{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection Lab\n",
    "\n",
    "In this lab we will explore feature selection on the Titanic Dataset. First of all let's load a few things:\n",
    "\n",
    "- Standard packages\n",
    "- The training set from lab 2.3\n",
    "- The union we have saved in lab 2.3\n",
    "\n",
    "\n",
    "You can load the titanic data as follows:\n",
    "\n",
    "    psql -h dsi.c20gkj5cvu3l.us-east-1.rds.amazonaws.com -p 5432 -U dsi_student titanic\n",
    "    password: gastudents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgresql://dsi_student:gastudents@dsi.c20gkj5cvu3l.us-east-1.rds.amazonaws.com/titanic')\n",
    "\n",
    "df = pd.read_sql('SELECT * FROM train', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5924806 ,  0.        ,  0.        , ...,  1.        ,\n",
       "         1.        , -0.50244517],\n",
       "       [ 0.63878901,  1.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.78684529],\n",
       "       [-0.2846632 ,  0.        ,  0.        , ...,  1.        ,\n",
       "         0.        , -0.48885426],\n",
       "       ..., \n",
       "       [ 0.        ,  0.        ,  0.        , ...,  1.        ,\n",
       "         0.        , -0.17626324],\n",
       "       [-0.2846632 ,  1.        ,  0.        , ...,  0.        ,\n",
       "         1.        , -0.04438104],\n",
       "       [ 0.17706291,  0.        ,  0.        , ...,  0.        ,\n",
       "         1.        , -0.49237783]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gzip\n",
    "import dill\n",
    "\n",
    "with gzip.open('C:/Users/Elizabeth/GA-DSI/curriculum/\\\n",
    "week-05/5.2-lab-titanic-features/assets/datasets/union.dill.gz') as fin:\n",
    "    union = dill.load(fin)\n",
    "    \n",
    "X = df[[u'Pclass', u'Sex', u'Age', u'SibSp', u'Parch', u'Fare', u'Embarked']]\n",
    "y = df[u'Survived']\n",
    "\n",
    "X_transf = union.fit_transform(X)\n",
    "X_transf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1 Column names\n",
    "\n",
    "Uh oh, we have lost the column names along the way! We need to manually add them:\n",
    "- age_pipe => 'scaled_age'\n",
    "- one_hot_pipe => 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Embarked_C', 'Embarked_Q', 'Embarked_S'\n",
    "- gender_pipe => 'male'\n",
    "- fare_pipe => 'scaled_fare'\n",
    "\n",
    "Now we need to:\n",
    "\n",
    "1. Create a new pandas dataframe called `Xt` with the appropriate column names and fill it with the `X_transf` data.\n",
    "2. Notice that the current pipeline complitely discards the columns: u'SibSp', u'Parch'. Stack them as they are to the new dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_cols = ['scaled_age', 'Pclass_1', 'Pclass_2', 'Pclass_3',\n",
    "            'Embarked_C', 'Embarked_Q', 'Embarked_S',\n",
    "            'male', 'scaled_fare']\n",
    "Xt = [df, X_transf]\n",
    "Xt.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Cols =[ ‘name’,’name2’,’name3’]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature selection\n",
    "\n",
    "Let's use the `SelectKBest` method in scikit learn to see which are the top 5 features.\n",
    "\n",
    "- What are the top 5 features for `Xt`?\n",
    "\n",
    "=> store them in a variable called `kbest_columns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Recursive Feature Elimination\n",
    "\n",
    "`Scikit Learn` also offers recursive feature elimination as a class named `RFECV`. Use it in combination with a logistic regression model to see what features would be kept with this method.\n",
    "\n",
    "=> store them in a variable called `rfecv_columns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Logistic regression coefficients\n",
    "\n",
    "Let's see if the Logistic Regression coefficients correspond.\n",
    "\n",
    "- Create a logistic regression model\n",
    "- Perform grid search over penalty type and C strength in order to find the best parameters\n",
    "- Sort the logistic regression coefficients by absolute value. Do the top 5 correspond to those above?\n",
    "> Answer: Not completely. That could be due to scaling\n",
    "\n",
    "=> choose which ones you would keep and store them in a variable called `lr_columns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compare features sets\n",
    "\n",
    "Use the `best estimator` from question 4 on the 3 different feature sets:\n",
    "\n",
    "- `kbest_columns`\n",
    "- `rfecv_columns`\n",
    "- `lr_columns`\n",
    "- `all_columns`\n",
    "\n",
    "Questions:\n",
    "\n",
    "- Which scores the highest? (use cross_val_score)\n",
    "- Is the difference significant?\n",
    "> Answer: Not really\n",
    "- discuss in pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "Use a bar chart to display the logistic regression coefficients. Start from the most negative on the left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
